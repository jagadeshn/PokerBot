{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Dropout , Activation , Flatten, Conv2D, MaxPooling2D\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from keras.optimizers import SGD\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#from keras.models import Sequential\n",
    "# #from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = r\"C:\\Users\\jagadesh\\Jupyter Projects\\PokerBazi\\cards\"\n",
    "DATADIR1 = r\"C:\\Users\\jagadesh\\Pictures\\cards\"\n",
    "lab_c = pd.read_csv(r\"C:\\Users\\jagadesh\\Jupyter Projects\\PokerBazi\\y_label1.csv\")\n",
    "file_path = r\"C:\\Users\\jagadesh\\Jupyter Projects\\PokerBazi\\y_label_shapes.csv\"\n",
    "SHAPES = r\"C:\\Users\\jagadesh\\Pictures\\new_cards\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"2c\",\"2d\",\"2h\",\"2s\",\"3c\",\"3d\",\"3h\",\"3s\",\"4c\",\"4d\",\n",
    "              \"4h\",\"4s\",\"5c\",\"5d\",\"5h\",\"5s\",\"6c\",\"6d\",\"6h\",\"6s\",\n",
    "              \"7c\",\"7d\",\"7h\",\"7s\",\"8c\",\"8d\",\"8h\",\"8s\",\"9c\",\"9d\",\n",
    "              \"9h\",\"9s\",\"10c\",\"10d\",\"10h\",\"10s\",\"Jc\",\"Jd\",\"Jh\",\n",
    "              \"Js\",\"Qc\",\"Qd\",\"Qh\",\"Qs\",\"Kc\",\"Kd\",\"Kh\",\"Ks\",\"Ac\",\n",
    "             \"Ad\",\"Ah\",\"As\"]\n",
    "SUIT = ['C','D','H','S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "count = 0\n",
    "IMG_SIZE = 30\n",
    "lolo = []\n",
    "\n",
    "def create_training_data():\n",
    "    count = 0\n",
    "    for category in SUIT:\n",
    "        \n",
    "        path = os.path.join(SHAPES, category)\n",
    "        class_num = SUIT.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            count = count + 1\n",
    "            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "            #new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)).flatten()\n",
    "            new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "            lolo.append([new_array,class_num])\n",
    "\n",
    "            \n",
    "            \n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X- (141, 30, 30)\n",
      "Shape of y- (141, 1)\n"
     ]
    }
   ],
   "source": [
    "lolo_shuffle = random.shuffle(lolo)\n",
    "X=[]\n",
    "y=[]\n",
    "for features , label in lolo:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE)\n",
    "y = np.transpose(np.array(y).reshape(-1,141))\n",
    "\n",
    "print(\"Shape of X-\" , X.shape)\n",
    "print(\"Shape of y-\" , y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Flatten(),\n",
    "    #Dense(900, activation='relu',),\n",
    "    #Dense(680, activation='relu'),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dense(80, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(4,activation='softmax') \n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "\n",
    "model2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model\n",
    "#check23 = model2.fit(X_train,y_train,batch_size=10,epochs =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check22 = model2.fit(X_train,y_train,batch_size=10,epochs =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check2 = model2.fit(X_train,y_train,batch_size=10,epochs =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score [3.4977104663848877, 0.8297872543334961]\n"
     ]
    }
   ],
   "source": [
    "scores = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Score',scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_SIZE, IMG_SIZE, 1)\n",
    "model3 = Sequential([\n",
    "        \n",
    "        Conv2D(32,(3,3), activation='relu',input_shape = input_shape ),\n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "    \n",
    "        Conv2D(64,(3,3), activation='relu'),        \n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "            \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "            \n",
    "        Dense(4, activation='softmax')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model3.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#model3.fit(X_train, y_train, epochs = 4, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#         rotation_range=40,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         fill_mode='nearest')\n",
    "\n",
    "# img = load_img('data/train/cats/cat.0.jpg')  # this is a PIL image\n",
    "# x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "# x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# # the .flow() command below generates batches of randomly transformed images\n",
    "# # and saves the results to the `preview/` directory\n",
    "# i = 0\n",
    "# for batch in datagen.flow(x, batch_size=1,\n",
    "#                           save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n",
    "#     i += 1\n",
    "#     if i > 20:\n",
    "#         break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), input_shape=(3, 150, 150)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training results\n",
    "# Now visualize the results after training the network.\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # saving pickle file\n",
    "# pickle_out = open(\"X.pickle\",\"wb\")\n",
    "# pickle.dump(X,pickle_out)\n",
    "# pickle_out.close()\n",
    "# pickle_out = open(\"y.pickle\",\"wb\")\n",
    "# pickle.dump(y,pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "# #to read again \n",
    "\n",
    "# import pickle\n",
    "# pickle_in = open(\"X.pickle\",\"rb\")\n",
    "# X = pickle.load(pickle_in)\n",
    "# pickle_in_y = open(\"y.pickle\",\"rb\")\n",
    "# y = pickle.load(pickle_in_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
